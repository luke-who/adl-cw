{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8574749",
   "metadata": {},
   "source": [
    "# Prelim experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07228f7a",
   "metadata": {
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import sys\n",
    "sys.path.insert(1, '../data/')\n",
    "import dataset\n",
    "from tensorflow.python.summary.summary_iterator import summary_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9d2855",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def loadDataset(datasetPath = '../ADL_DCASE_DATA/'):\n",
    "    \n",
    "    def loadAudio(path):\n",
    "        files = listdir(path)\n",
    "        audioDataset = []\n",
    "        for file in files:\n",
    "            audioDataset.append((file, np.load(path + \"/\" + file)))\n",
    "        return audioDataset\n",
    "    \n",
    "    def loadCSV(path):\n",
    "        return pd.read_csv(path, names = [\"file\",\"category\"], index_col = \"file\")\n",
    "    \n",
    "    def getFileCategory(InputFeat, OutputFeat):\n",
    "        return [(OutputFeat.loc[file][0], audio) for (file, audio) in InputFeat]\n",
    "    \n",
    "#     trainingInput = loadAudio(datasetPath + \"development/audio\")\n",
    "    \n",
    "    trainingGroundTruth = loadCSV(datasetPath + \"development/labels.csv\")\n",
    "        \n",
    "#     trainingDataset = getFileCategory(trainingInput, trainingGroundTruth)\n",
    "\n",
    "    \n",
    "    return trainingGroundTruth[\"category\"].tolist()\n",
    "    \n",
    "    \n",
    "categories = loadDataset()\n",
    "ind_categories = []\n",
    "for category in categories:\n",
    "    if category not in ind_categories:\n",
    "        ind_categories.append(category)\n",
    "        \n",
    "\n",
    "print(ind_categories)\n",
    "print(len(ind_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879c344c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class AudioEnviromentDataset(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.fileCategory = pd.read_csv(self.root_dir + \"/labels.csv\", names = [\"file\",\"category\"])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fileCategory)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file = self.fileCategory.iloc[idx][\"file\"]\n",
    "        category = ind_categories.index(self.fileCategory.iloc[idx][\"category\"])\n",
    "        return np.load(self.root_dir + \"/audio/\" + file).reshape(-1, 60, 1501), category\n",
    "    \n",
    "training_data = AudioEnviromentDataset(\"../ADL_DCASE_DATA/development\")\n",
    "test_dataloader = AudioEnviromentDataset(\"../ADL_DCASE_DATA/evaluation\")\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size = 32)\n",
    "test_dataloader = DataLoader(training_data, batch_size = 32)\n",
    "\n",
    "print(training_data[0][0].shape)\n",
    "print(training_data[0][1])\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(training_data[0][0][0], aspect=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54028d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # 60, 1501\n",
    "# y = 60\n",
    "# x = 1501\n",
    "\n",
    "\n",
    "# y = y\n",
    "# x = x\n",
    "\n",
    "# x = x / 2\n",
    "# y = y / 2\n",
    "\n",
    "# x = x / 2\n",
    "# y = y / 2\n",
    "\n",
    "# print(64 * x * y)\n",
    "# print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4609e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "class AudioCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn_neuro_stack = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=16,\n",
    "                kernel_size=(5, 5),\n",
    "                padding=(2, 2),\n",
    "            ),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),\n",
    "            \n",
    "            nn.Conv2d(\n",
    "                in_channels=16,\n",
    "                out_channels=2,\n",
    "                kernel_size=(5, 5),\n",
    "                padding=(2, 2),\n",
    "            ),\n",
    "            nn.BatchNorm2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),\n",
    "            \n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.BatchNorm1d(11250),\n",
    "            nn.Linear(11250,1000),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.BatchNorm1d(1000),\n",
    "            nn.Linear(1000,15)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.cnn_neuro_stack(x)\n",
    "        return logits\n",
    "    \n",
    "\n",
    "model = AudioCNN().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199ab417",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loss = nn.CrossEntropyLoss()\n",
    "# a = torch.randn(3, 5, requires_grad=True)\n",
    "# b = torch.empty(3, dtype=torch.long).random_(5)\n",
    "# print(a.shape)\n",
    "# print(b.shape)\n",
    "# loss(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a332a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 5 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "        \n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")        \n",
    "\n",
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45297b8f",
   "metadata": {},
   "source": [
    "# Writing training file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b2a868",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = dataset.DCASE(\"../data/ADL_DCASE_DATA/development/\", 30)\n",
    "print(\"datapoints:\", len(training_data))\n",
    "print(\"segments per point:\", len(training_data[0][0]))\n",
    "plt.imshow(training_data[1][0][0], aspect=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e728c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_data = dataset.DCASE(\"../data/ADL_DCASE_DATA/development/\", 10)\n",
    "plt.figure(figsize=(15,15))\n",
    "print(\"datapoints:\", len(training_data))\n",
    "print(\"segments per point:\", len(training_data[0][0]))\n",
    "print(\"shape:\",training_data[0][0].shape)\n",
    "plt.imshow(training_data[1][0][0], aspect=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c61d8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_data = dataset.DCASE(\"../data/ADL_DCASE_DATA/development/\" , 3)\n",
    "print(\"segments per point:\", len(training_data[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08266dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = dataset.DCASE_clip(\"../data/ADL_DCASE_DATA/development/\" , 3, normData=True)\n",
    "print(\"segments per point:\", training_data.get_num_clips())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcec6b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "divmod(1999,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388d04bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f494f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data._clip_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fac967d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.normData = False\n",
    "plt.imshow(training_data[1][0][0], aspect=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11ee6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.normData = True\n",
    "plt.imshow(training_data[1][0][0], aspect=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed84fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.normData = True\n",
    "plt.imshow(training_data[1][0][0], aspect=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acae750b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b51a43c",
   "metadata": {},
   "source": [
    "# train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b618ab74",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = dataset.DCASE_clip(\"../data/ADL_DCASE_DATA/development/\" , 3, normData=True)\n",
    "testing_data = dataset.DCASE_clip(\"../data/ADL_DCASE_DATA/development/\" , 3)\n",
    "print(len(training_data))\n",
    "print(len(testing_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbfb3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(training_data[1][0][0], aspect=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29463aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split, test_split = training_data.split(train_rat = 0.7, shuffle = True)\n",
    "print(len(training_data))\n",
    "print(len(train_split))\n",
    "print(len(test_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308c9b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split._labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f408da9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sum_arr = 0\n",
    "time_len = len(training_data[0][0][0,0])\n",
    "items = len(training_data)\n",
    "\n",
    "for i in range (0,items):\n",
    "    sum_arr += training_data[i][0][0,5].sum()\n",
    "    \n",
    "sum_arr/(time_len*items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f521455",
   "metadata": {},
   "source": [
    "# Time offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57832534",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dataset = dataset.DCASE_clip(\"../data/ADL_DCASE_DATA/development/\" , 30, offSet = True, normData=True)\n",
    "sub_dataset = dataset.DCASE_clip(\"../data/ADL_DCASE_DATA/development/\" , 3, offSet = True, normData=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9571ed7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.roll(main_dataset[0][0][0], 0), aspect=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49bbec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sub_dataset[1][0][0], aspect=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1027e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sub_dataset[0][0][0], aspect=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611d31fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(6).reshape(2,3)\n",
    "midpoint = (a.max() + a.min())/2\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.matshow(a, cmap='Greens')\n",
    "ax.set_xticks(range(3))\n",
    "ax.set_yticks(range(2))\n",
    "ax.set_xticklabels([\"pee\",\"poo\",\"fart\"])\n",
    "ax.set_xlabel(\"What happened\")\n",
    "ax.set_yticklabels([\"pee\",\"poo\"])\n",
    "ax.set_ylabel(\"What happens next\")\n",
    "\n",
    "for (i, j), z in np.ndenumerate(a):\n",
    "    if z > midpoint:\n",
    "        ax.text(j, i, '{:1}'.format(z), color='white')\n",
    "    else:\n",
    "        ax.text(j, i, '{:1}'.format(z))\n",
    "\n",
    "# fig.canvas.draw()\n",
    "# img = np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep='')\n",
    "# img = img.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "# img = img / 255.0\n",
    "\n",
    "# print(fig.canvas.tostring_rgb())\n",
    "\n",
    "canvas = FigureCanvas(fig)\n",
    "canvas.draw()\n",
    "\n",
    "image = np.array(canvas.renderer.buffer_rgba())\n",
    "image = image/255\n",
    "fig, ax = plt.subplots()\n",
    "print(image.shape)\n",
    "plt.imshow(image)\n",
    "image_y, image_x = image.shape[0], image.shape[1]\n",
    "image = image[:,:,0:3].reshape(3, image_y, image_x)\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c20fcca",
   "metadata": {},
   "source": [
    "# Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38aaf076",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Parsing TensorBoard data locally\n",
    "\n",
    "# Dawid Laszuk + Ben Jones\n",
    "\n",
    "def convert_tb_data(root_dir, sort_by=None):\n",
    "    def convert_tfevent(filepath):\n",
    "        parent_name = os.path.basename(os.path.dirname(filepath))\n",
    "        return pd.DataFrame([\n",
    "            parse_tfevent(e, parent_name) for e in summary_iterator(filepath) if len(e.summary.value)\n",
    "        ])\n",
    "\n",
    "    def parse_tfevent(tfevent, parent_name):\n",
    "        return dict(\n",
    "            wall_time=tfevent.wall_time,\n",
    "            parent_name=parent_name,\n",
    "            scalar_name=tfevent.summary.value[0].tag,\n",
    "            step=tfevent.step,\n",
    "            value=float(tfevent.summary.value[0].simple_value),\n",
    "        )\n",
    "    \n",
    "    columns_order = ['wall_time', 'parent_name', 'scalar_name', 'step', 'value']\n",
    "    \n",
    "    out = []\n",
    "    for (root, _, filenames) in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            if \"events.out.tfevents\" not in filename:\n",
    "                continue\n",
    "            file_full_path = os.path.join(root, filename)\n",
    "            out.append(convert_tfevent(file_full_path))\n",
    "\n",
    "    # Concatenate (and sort) all partial individual dataframes\n",
    "    all_df = pd.concat(out)[columns_order]\n",
    "    if sort_by is not None:\n",
    "        all_df = all_df.sort_values(sort_by)\n",
    "        \n",
    "    return all_df.reset_index(drop=True)\n",
    "\n",
    "df = convert_tb_data(\"bc_logs/copyfix/CNN_bn_bs=64_lr=0.0005_train_ratio=0.7valid_frequency=2_max_worsen_streak=5_run_0/\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e61a808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotAll(df, smoothing = 0.5):\n",
    "    scalar_names = pd.unique(df['scalar_name'])\n",
    "    fig, ax = plt.subplots(len(scalar_names), 1, figsize=(15,5*len(scalar_names)))\n",
    "    for i, scalar_name in enumerate(scalar_names):\n",
    "        scalar = df.loc[df['scalar_name'] == scalar_name]\n",
    "        parent_names = pd.unique(scalar['parent_name'])\n",
    "        for parent_name in parent_names:\n",
    "            contex_scalar = df.loc[df['parent_name'] == parent_name]\n",
    "            ax[i].plot(contex_scalar['step'], contex_scalar['value'].ewm(com=smoothing).mean(), label=parent_name)\n",
    "        ax[i].set_xlabel(\"Steps.\")\n",
    "        ax[i].set_ylabel(scalar_name)\n",
    "        ax[i].legend()\n",
    "        ax[i].grid()\n",
    "            \n",
    "plotAll(df, smoothing = 1.6)\n",
    "\n",
    "# df.loc[(df['scalar_name'] == \"class_accuracy_full_test\") & (df['parent_name'] == \"class_accuracy_full_test_13\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf189f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plotSome(df, smoothing = 0.5, figsize = (6,5)):\n",
    "#     scalar_names = pd.unique(df['scalar_name'])\n",
    "#     fig, ax = plt.subplots(figsize=(15,5*len(scalar_names)))\n",
    "#     for i, scalar_name in enumerate(scalar_names):\n",
    "#         scalar = df.loc[df['scalar_name'] == scalar_name]\n",
    "#         parent_names = pd.unique(scalar['parent_name'])\n",
    "#         for parent_name in parent_names:\n",
    "#             contex_scalar = df.loc[df['parent_name'] == parent_name]\n",
    "#             ax[i].plot(contex_scalar['step'], contex_scalar['value'].ewm(com=smoothing).mean(), label=parent_name)\n",
    "#             ax[i].set_xlabel(\"Steps.\")\n",
    "#             ax[i].set_ylabel(scalar_name)\n",
    "#             ax[i].legend()\n",
    "#             ax[i].grid()\n",
    "            \n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    parent_names = [\"loss_nonfull_train\", \"loss_nonfull_test\", \"loss_nonfull_validation\"]\n",
    "    for parent_name in parent_names:\n",
    "        contex_scalar = df.loc[df['parent_name'] == parent_name]\n",
    "        ax.plot(contex_scalar['step'], contex_scalar['value'].ewm(com=smoothing).mean(), label=parent_name)\n",
    "        ax.set_xlabel(\"Steps.\")\n",
    "        ax.set_ylabel(\"Loss.\")\n",
    "        ax.legend()\n",
    "        ax.grid()\n",
    "    fig.savefig(\"svg/loss_nonfull.svg\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    parent_names = [\"loss_full_train\", \"loss_full_test\"]\n",
    "    for parent_name in parent_names:\n",
    "        contex_scalar = df.loc[df['parent_name'] == parent_name]\n",
    "        ax.plot(contex_scalar['step'], contex_scalar['value'].ewm(com=smoothing).mean(), label=parent_name)\n",
    "        ax.set_xlabel(\"Steps.\")\n",
    "        ax.set_ylabel(\"Loss.\")\n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "    fig.savefig(\"svg/loss_full.svg\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    parent_names = [\"accuracy_nonfull_train\", \"accuracy_nonfull_validation\", \"accuracy_nonfull_test\"]\n",
    "    for parent_name in parent_names:\n",
    "        contex_scalar = df.loc[df['parent_name'] == parent_name]\n",
    "        ax.plot(contex_scalar['step'], contex_scalar['value'].ewm(com=smoothing).mean(), label=parent_name)\n",
    "        ax.set_xlabel(\"Steps.\")\n",
    "        ax.set_ylabel(\"Accuracy (%)\")\n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "    fig.savefig(\"svg/accuracy_nonfull.svg\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    parent_names = [\"accuracy_full_train\", \"accuracy_full_test\"]\n",
    "    for parent_name in parent_names:\n",
    "        contex_scalar = df.loc[df['parent_name'] == parent_name]\n",
    "        ax.plot(contex_scalar['step'], contex_scalar['value'].ewm(com=smoothing).mean(), label=parent_name)\n",
    "        ax.set_xlabel(\"Steps.\")\n",
    "        ax.set_ylabel(\"Accuracy (%)\")\n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "    fig.savefig(\"svg/accuracy_full.svg\")\n",
    "\n",
    "plotSome(df, smoothing = 0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
