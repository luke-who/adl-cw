{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"run_dcase_collab.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1kyaTQbC9Y3YXLdCyRoEMhVfCcErdKRIL","authorship_tag":"ABX9TyM1KHElSfHMntTEJAZ0oMdS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m5_B4RJ4GK6S","outputId":"3f2ef4a0-cb09-47ee-b1ce-ec321bc0e906","executionInfo":{"status":"ok","timestamp":1639081241503,"user_tz":0,"elapsed":883587,"user":{"displayName":"Luke Z","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRV1wZ6kdkycjAOaOsCVbS_9SRNw6b1I9x4WBv=s64","userId":"03291988054166368634"}}},"source":["!python /content/drive/MyDrive/Colab\\ Notebooks/adl-cw/work/dcase.py --epochs 1"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Using cpu device.\n","Computing norm.\n","Done.\n","Using proir norm.\n","Total number of classes/categories: 15\n","Writing logs to logs/CNN_bn_bs=64_lr=0.0005_run_0\n","Epoch 1/1\n","-------------------------------------------------------------\n","loss: 3.186720, [    0/ 8190], batch=  1/128, current_bsize= 64, baccuracy:  7.8%, bclass_accuracy:[  0, 50,  0,  0,  0,  0,  0,  0, 40,  0,  0,  0, 50,  0,  0,]\n","loss: 2.736831, [   64/ 8190], batch=  2/128, current_bsize= 64, baccuracy: 17.2%, bclass_accuracy:[  0,  0,100,100,  0,  0,  0, 80,  0,  0,  0,  0,  0,  0,  0,]\n","loss: 2.709894, [  128/ 8190], batch=  3/128, current_bsize= 64, baccuracy: 20.3%, bclass_accuracy:[ 62,  0,  0,  0,  0, 40,100,  0,  0,100,  0, 14,  0,  0,  0,]\n","loss: 2.244363, [  192/ 8190], batch=  4/128, current_bsize= 64, baccuracy: 32.8%, bclass_accuracy:[100,  0,  0,  0,100, 80,  0, 33, 38,  0,100, 29,  0,100,  0,]\n","loss: 2.488763, [  256/ 8190], batch=  5/128, current_bsize= 64, baccuracy: 15.6%, bclass_accuracy:[ 50,  0,  0,  0,100,  0,  0, 33, 75,  0,100,  0,  0,  0,  0,]\n","loss: 2.409167, [  320/ 8190], batch=  6/128, current_bsize= 64, baccuracy: 23.4%, bclass_accuracy:[ 50, 60,  0,  0,  0,  0,  0, 50, 60,  0,  0, 17,100,  0,  0,]\n","loss: 2.077514, [  384/ 8190], batch=  7/128, current_bsize= 64, baccuracy: 23.4%, bclass_accuracy:[ 67, 75,  0,  0, 50,  0,  0, 67,  0,100, 50,  0,100,  0,  0,]\n","loss: 2.021751, [  448/ 8190], batch=  8/128, current_bsize= 64, baccuracy: 23.4%, bclass_accuracy:[  0,100,  0,  0,  0,  0,  0, 50,  0,  0,100,  0, 86,  0,  0,]\n","loss: 2.005970, [  512/ 8190], batch=  9/128, current_bsize= 64, baccuracy: 28.1%, bclass_accuracy:[  0,100, 17,100,  0, 33,  0, 64, 20,  0,100,  0, 40,  0,  0,]\n","loss: 1.966592, [  576/ 8190], batch= 10/128, current_bsize= 64, baccuracy: 29.7%, bclass_accuracy:[ 20,  0, 25, 75,100, 20, 20, 71, 14,  0,100,  0, 40, 50,  0,]\n","loss: 2.066994, [  640/ 8190], batch= 11/128, current_bsize= 64, baccuracy: 39.1%, bclass_accuracy:[ 10,  0,100,100,  0, 40, 25,100,  0, 17,100, 43, 29,100, 50,]\n","loss: 1.950494, [  704/ 8190], batch= 12/128, current_bsize= 64, baccuracy: 35.9%, bclass_accuracy:[ 40, 17,100, 67,  0, 40,  0, 67, 25,  0,100, 50, 25,  0,  0,]\n","loss: 1.881673, [  768/ 8190], batch= 13/128, current_bsize= 64, baccuracy: 35.9%, bclass_accuracy:[ 25,  0,100, 67,  0, 62, 33, 50,  0, 40,  0, 50, 25,  0,  0,]\n","loss: 1.834579, [  832/ 8190], batch= 14/128, current_bsize= 64, baccuracy: 37.5%, bclass_accuracy:[ 43,  0,100,100,  0, 88, 50, 40,  0, 20,  0, 50,  0,  0,  0,]\n","loss: 1.836600, [  896/ 8190], batch= 15/128, current_bsize= 64, baccuracy: 39.1%, bclass_accuracy:[ 75,  0, 67,100,  0,100, 67, 38,  0, 50,  0, 60, 20,  0, 33,]\n","loss: 1.967188, [  960/ 8190], batch= 16/128, current_bsize= 64, baccuracy: 37.5%, bclass_accuracy:[100,  0, 29,100, 67, 75, 14,100,  0, 67,100, 40, 12,  0, 67,]\n","loss: 1.680117, [ 1024/ 8190], batch= 17/128, current_bsize= 64, baccuracy: 46.9%, bclass_accuracy:[ 89,  0, 14,100,  0, 75,  0, 33,  0, 20, 33, 50, 57,100, 67,]\n","loss: 1.648386, [ 1088/ 8190], batch= 18/128, current_bsize= 64, baccuracy: 39.1%, bclass_accuracy:[ 33,  0, 20,100,100, 33, 25, 33,  0,  0,100, 71, 17,  0, 50,]\n","loss: 1.639179, [ 1152/ 8190], batch= 19/128, current_bsize= 64, baccuracy: 40.6%, bclass_accuracy:[100,  0, 50,100,  0, 60,  0, 33,  0,  0,100, 67, 10,  0, 67,]\n","loss: 1.440065, [ 1216/ 8190], batch= 20/128, current_bsize= 64, baccuracy: 56.2%, bclass_accuracy:[ 83, 33, 80, 50, 75, 20,100,100, 55,  0,100, 71,  0,  0, 20,]\n","loss: 1.525326, [ 1280/ 8190], batch= 21/128, current_bsize= 64, baccuracy: 43.8%, bclass_accuracy:[ 67,  0, 75,100,100, 33,  0, 86, 71,  0,100, 17, 40,  0, 50,]\n","loss: 1.495360, [ 1344/ 8190], batch= 22/128, current_bsize= 64, baccuracy: 51.6%, bclass_accuracy:[ 86, 40, 78, 67,100, 33, 33, 50, 33,  0, 50, 50, 33, 75, 33,]\n","loss: 1.598859, [ 1408/ 8190], batch= 23/128, current_bsize= 64, baccuracy: 50.0%, bclass_accuracy:[ 29,  0,100, 67,  0, 50,100, 80, 33,  0, 50, 20, 86, 50, 75,]\n","loss: 1.486022, [ 1472/ 8190], batch= 24/128, current_bsize= 64, baccuracy: 45.3%, bclass_accuracy:[ 50,  0,100, 60,  0, 40, 50, 60, 80,  0,  0, 40, 33,100,  0,]\n","loss: 1.639440, [ 1536/ 8190], batch= 25/128, current_bsize= 64, baccuracy: 50.0%, bclass_accuracy:[ 80,100, 80, 75,  0, 86, 25, 50, 57,  0, 50, 33, 20, 50, 67,]\n","loss: 1.600025, [ 1600/ 8190], batch= 26/128, current_bsize= 64, baccuracy: 51.6%, bclass_accuracy:[ 43,100,100,100,100, 80,  0, 75, 67,  0,100, 62, 29,  0, 15,]\n","loss: 1.894444, [ 1664/ 8190], batch= 27/128, current_bsize= 64, baccuracy: 42.2%, bclass_accuracy:[ 57,100,100,  0,  0, 71, 33, 33,  0, 40, 50, 38, 43,  0, 33,]\n","loss: 1.557035, [ 1728/ 8190], batch= 28/128, current_bsize= 64, baccuracy: 48.4%, bclass_accuracy:[ 50, 50,100,100,  0, 60, 33, 75,  0, 40, 50,  0, 62,  0,100,]\n","loss: 1.499400, [ 1792/ 8190], batch= 29/128, current_bsize= 64, baccuracy: 57.8%, bclass_accuracy:[ 57,  0, 67,100,100, 86, 67, 71, 25, 33, 75, 75, 80,  0, 50,]\n","loss: 1.562442, [ 1856/ 8190], batch= 30/128, current_bsize= 64, baccuracy: 50.0%, bclass_accuracy:[ 67,  0, 60,100,  0, 88,  0, 80, 67,100,100, 40, 46,  0,  0,]\n","loss: 1.286543, [ 1920/ 8190], batch= 31/128, current_bsize= 64, baccuracy: 60.9%, bclass_accuracy:[ 71,  0, 50, 60,100, 67, 67, 62,100, 50,100, 83, 70,  0, 60,]\n","loss: 1.510848, [ 1984/ 8190], batch= 32/128, current_bsize= 64, baccuracy: 42.2%, bclass_accuracy:[ 60,  0, 67, 80,100, 40, 75, 25, 67, 40,  0, 33, 30,  0, 40,]\n","loss: 1.205282, [ 2048/ 8190], batch= 33/128, current_bsize= 64, baccuracy: 67.2%, bclass_accuracy:[ 86,  0,100,100,100, 60, 60, 57, 50,100,100, 33, 83,100, 67,]\n","loss: 1.301542, [ 2112/ 8190], batch= 34/128, current_bsize= 64, baccuracy: 59.4%, bclass_accuracy:[100, 33, 67,100,  0, 67,100, 78, 75,  0,100, 33, 50, 60, 33,]\n","loss: 1.308270, [ 2176/ 8190], batch= 35/128, current_bsize= 64, baccuracy: 54.7%, bclass_accuracy:[ 75, 33, 60,  0,100, 50,100, 67, 80,  0,100,  0, 89, 50,  0,]\n","loss: 1.235513, [ 2240/ 8190], batch= 36/128, current_bsize= 64, baccuracy: 60.9%, bclass_accuracy:[ 33, 67, 83,100, 50, 67, 75,100, 60,  0,100,  0, 67, 60, 33,]\n","loss: 1.255187, [ 2304/ 8190], batch= 37/128, current_bsize= 64, baccuracy: 64.1%, bclass_accuracy:[100,100,100,  0,  0, 67, 50, 50, 67,  0, 75, 50, 75,100, 75,]\n","loss: 1.252576, [ 2368/ 8190], batch= 38/128, current_bsize= 64, baccuracy: 64.1%, bclass_accuracy:[ 80, 83,100, 50,  0,100, 50, 71, 60, 60,100, 50, 57, 33, 33,]\n","loss: 1.131741, [ 2432/ 8190], batch= 39/128, current_bsize= 64, baccuracy: 65.6%, bclass_accuracy:[ 78,100, 67,100, 67, 70, 60, 56,100, 33, 75, 83, 33, 25,100,]\n","loss: 1.124155, [ 2496/ 8190], batch= 40/128, current_bsize= 64, baccuracy: 64.1%, bclass_accuracy:[100, 67, 80, 50, 60, 78, 33,100, 83,100,100, 25,  0, 60,100,]\n","loss: 1.118478, [ 2560/ 8190], batch= 41/128, current_bsize= 64, baccuracy: 64.1%, bclass_accuracy:[ 29, 89,100,100, 75,100, 40, 75, 33,100,100, 57,  0, 67, 60,]\n","loss: 1.273294, [ 2624/ 8190], batch= 42/128, current_bsize= 64, baccuracy: 57.8%, bclass_accuracy:[ 50,100, 33,100,  0, 75,  0, 86, 83, 75,100,100, 23,  0, 40,]\n","loss: 1.191093, [ 2688/ 8190], batch= 43/128, current_bsize= 64, baccuracy: 62.5%, bclass_accuracy:[ 80,100, 75,100, 25, 40,  0, 71,100, 67,100, 50, 25, 33,100,]\n","loss: 1.351902, [ 2752/ 8190], batch= 44/128, current_bsize= 64, baccuracy: 59.4%, bclass_accuracy:[ 77,  0, 86,100,100, 67, 50, 71, 80,100,100, 33, 20, 14,100,]\n","loss: 1.106362, [ 2816/ 8190], batch= 45/128, current_bsize= 64, baccuracy: 64.1%, bclass_accuracy:[ 67, 67, 83,100, 33, 71, 50, 62,100, 57,100, 50, 67,100, 20,]\n","loss: 1.217629, [ 2880/ 8190], batch= 46/128, current_bsize= 64, baccuracy: 62.5%, bclass_accuracy:[100,100,100, 75,  0, 50, 20, 75, 57, 50, 80,  0, 83,100,100,]\n","loss: 1.140876, [ 2944/ 8190], batch= 47/128, current_bsize= 64, baccuracy: 64.1%, bclass_accuracy:[100,100,100, 67,100, 60,  0, 80, 67,100,100,  0, 70, 60, 33,]\n","loss: 1.169662, [ 3008/ 8190], batch= 48/128, current_bsize= 64, baccuracy: 62.5%, bclass_accuracy:[100, 50,100,100,100, 54, 50, 50, 50, 50,100,  0, 50,100,100,]\n","loss: 1.218511, [ 3072/ 8190], batch= 49/128, current_bsize= 64, baccuracy: 60.9%, bclass_accuracy:[ 80,100,100,100,  0, 75, 80, 75, 33, 33,100, 17, 67, 75, 50,]\n","loss: 1.121549, [ 3136/ 8190], batch= 50/128, current_bsize= 64, baccuracy: 68.8%, bclass_accuracy:[100, 33, 83,100,  0, 71,  0, 40, 71, 67,100, 67, 83, 25,100,]\n","loss: 0.961479, [ 3200/ 8190], batch= 51/128, current_bsize= 64, baccuracy: 70.3%, bclass_accuracy:[ 70,  0,100, 83,100,100, 80, 60, 50, 40,100, 67, 25,100,100,]\n","loss: 0.886009, [ 3264/ 8190], batch= 52/128, current_bsize= 64, baccuracy: 78.1%, bclass_accuracy:[ 82,100, 75,100,100,100,100, 50, 88, 75, 75, 71, 50,100, 50,]\n","loss: 0.970593, [ 3328/ 8190], batch= 53/128, current_bsize= 64, baccuracy: 65.6%, bclass_accuracy:[100, 50,100, 50,100, 83,  0, 43, 50, 60,100, 75, 50,  0, 67,]\n","loss: 1.223684, [ 3392/ 8190], batch= 54/128, current_bsize= 64, baccuracy: 64.1%, bclass_accuracy:[ 73, 67,100,100, 33,100, 40, 67, 33,  0,100,100, 20,100, 25,]\n","loss: 0.996305, [ 3456/ 8190], batch= 55/128, current_bsize= 64, baccuracy: 70.3%, bclass_accuracy:[ 50,100, 71,100,  0, 67,  0,100, 60,100,100,100, 33, 25, 67,]\n","loss: 0.955616, [ 3520/ 8190], batch= 56/128, current_bsize= 64, baccuracy: 73.4%, bclass_accuracy:[ 67,100, 67,100, 57, 67, 67,100, 83,100,100, 86, 71, 67,  0,]\n","loss: 1.022974, [ 3584/ 8190], batch= 57/128, current_bsize= 64, baccuracy: 64.1%, bclass_accuracy:[ 62,100, 86,100,  0, 67,  0, 60,100, 80,100, 33, 20, 50, 75,]\n","loss: 0.923630, [ 3648/ 8190], batch= 58/128, current_bsize= 64, baccuracy: 67.2%, bclass_accuracy:[ 75, 75,100,100,100, 83, 25, 60, 86, 50, 75, 44, 75, 25, 67,]\n","loss: 0.947508, [ 3712/ 8190], batch= 59/128, current_bsize= 64, baccuracy: 67.2%, bclass_accuracy:[ 50, 67, 75, 50,100, 50,100,100,100, 67,100, 25, 67, 50, 50,]\n","loss: 0.880857, [ 3776/ 8190], batch= 60/128, current_bsize= 64, baccuracy: 67.2%, bclass_accuracy:[100,100, 70,100,100,100, 67, 75, 50, 50, 60, 33, 57,  0, 67,]\n","loss: 0.865884, [ 3840/ 8190], batch= 61/128, current_bsize= 64, baccuracy: 71.9%, bclass_accuracy:[ 75,100,100, 67,100,100,100, 75, 80,  0,100, 56, 25,100, 75,]\n","loss: 0.846229, [ 3904/ 8190], batch= 62/128, current_bsize= 64, baccuracy: 68.8%, bclass_accuracy:[ 50,100,100,  0, 33,100,100, 60, 75, 67,100, 50, 50,100, 50,]\n","loss: 0.950393, [ 3968/ 8190], batch= 63/128, current_bsize= 64, baccuracy: 65.6%, bclass_accuracy:[100,100, 83, 67, 60, 86,100, 62, 80,  0, 50, 40, 60, 33, 67,]\n","loss: 0.919536, [ 4032/ 8190], batch= 64/128, current_bsize= 64, baccuracy: 73.4%, bclass_accuracy:[ 75, 50,100,  0,100, 73,100,100, 62,100,100, 67, 43, 75,100,]\n","loss: 0.800858, [ 4096/ 8190], batch= 65/128, current_bsize= 64, baccuracy: 75.0%, bclass_accuracy:[ 38, 67,100, 67,100, 78,100,100,100, 80,100,100, 25,100, 57,]\n","loss: 0.695233, [ 4160/ 8190], batch= 66/128, current_bsize= 64, baccuracy: 82.8%, bclass_accuracy:[ 88,100,100, 75, 33,100,100, 83, 67,100,100,100, 40,100, 75,]\n","loss: 0.934122, [ 4224/ 8190], batch= 67/128, current_bsize= 64, baccuracy: 71.9%, bclass_accuracy:[ 89, 25, 25,100, 50,100,100,100,  0, 75,100,100, 25, 40, 60,]\n","loss: 0.694867, [ 4288/ 8190], batch= 68/128, current_bsize= 64, baccuracy: 81.2%, bclass_accuracy:[100, 33,100,100,100,100, 75,100, 33,100,100, 60, 50,  0,100,]\n","loss: 1.166281, [ 4352/ 8190], batch= 69/128, current_bsize= 64, baccuracy: 64.1%, bclass_accuracy:[ 86, 25,100, 75, 25,100,  0, 67, 75, 67,100,100, 43,  0, 67,]\n","loss: 0.767867, [ 4416/ 8190], batch= 70/128, current_bsize= 64, baccuracy: 75.0%, bclass_accuracy:[ 86, 67,100,100,100,100, 50, 80,100,100, 75, 33, 83,  0, 50,]\n","loss: 0.832132, [ 4480/ 8190], batch= 71/128, current_bsize= 64, baccuracy: 65.6%, bclass_accuracy:[ 50, 40, 67, 83,100, 80, 33,100,100, 75,100, 20, 50, 60,100,]\n","loss: 0.798649, [ 4544/ 8190], batch= 72/128, current_bsize= 64, baccuracy: 75.0%, bclass_accuracy:[ 75, 67, 75,100, 75,100, 75,100,100, 67,100, 22,100, 67, 75,]\n","loss: 0.928687, [ 4608/ 8190], batch= 73/128, current_bsize= 64, baccuracy: 65.6%, bclass_accuracy:[ 62, 67, 83,100, 50, 80,100, 67, 71,100,100, 67, 83,  0,  0,]\n","loss: 0.656689, [ 4672/ 8190], batch= 74/128, current_bsize= 64, baccuracy: 79.7%, bclass_accuracy:[ 88,100,100,100,100,100, 50, 75, 50, 67, 83, 25,100,  0, 50,]\n","loss: 0.949964, [ 4736/ 8190], batch= 75/128, current_bsize= 64, baccuracy: 57.8%, bclass_accuracy:[ 50,100, 50, 80,100,100, 67, 80, 67, 67,100, 50, 20, 50,  0,]\n","loss: 0.725592, [ 4800/ 8190], batch= 76/128, current_bsize= 64, baccuracy: 75.0%, bclass_accuracy:[ 67,100,100, 67, 67,100,  0, 75,100, 50,100, 71, 38,100,100,]\n","loss: 0.803403, [ 4864/ 8190], batch= 77/128, current_bsize= 64, baccuracy: 65.6%, bclass_accuracy:[ 83,100,100,100,  0, 83, 62, 75, 20,100,100,100,  0, 43, 80,]\n","loss: 1.061422, [ 4928/ 8190], batch= 78/128, current_bsize= 64, baccuracy: 59.4%, bclass_accuracy:[ 67,  0,100,  0,  0, 75, 25, 57, 67, 33,100,100, 50, 67,100,]\n","loss: 1.015342, [ 4992/ 8190], batch= 79/128, current_bsize= 64, baccuracy: 71.9%, bclass_accuracy:[100, 50, 75, 33,100, 60,100, 88, 67, 67,100,100, 29, 50,100,]\n","loss: 0.653328, [ 5056/ 8190], batch= 80/128, current_bsize= 64, baccuracy: 75.0%, bclass_accuracy:[ 67,100,100,100, 50,100, 60,100,100, 50,100, 40, 43, 75, 75,]\n","loss: 0.732264, [ 5120/ 8190], batch= 81/128, current_bsize= 64, baccuracy: 79.7%, bclass_accuracy:[100,100,100,100,100,100, 67,100, 33, 67,  0, 75, 78,100, 50,]\n","loss: 0.699946, [ 5184/ 8190], batch= 82/128, current_bsize= 64, baccuracy: 76.6%, bclass_accuracy:[100,  0, 75,100,100,100,100, 86, 78,100,100, 33, 67, 67, 50,]\n","loss: 0.672730, [ 5248/ 8190], batch= 83/128, current_bsize= 64, baccuracy: 68.8%, bclass_accuracy:[ 57,  0, 88,100,  0,100,100,100,100, 67,100, 57, 83, 67,  0,]\n","loss: 0.946773, [ 5312/ 8190], batch= 84/128, current_bsize= 64, baccuracy: 75.0%, bclass_accuracy:[ 80,100,100,100,100,100,100, 60, 75,100, 80, 43, 67, 33, 33,]\n","loss: 0.665486, [ 5376/ 8190], batch= 85/128, current_bsize= 64, baccuracy: 78.1%, bclass_accuracy:[ 80,  0,100,100,100,100, 67, 60, 71, 75,100, 75, 57,100,100,]\n","loss: 0.956915, [ 5440/ 8190], batch= 86/128, current_bsize= 64, baccuracy: 73.4%, bclass_accuracy:[ 80,100, 88,100,100, 71, 75, 86,100,100,100, 60, 33, 67, 50,]\n","loss: 0.675896, [ 5504/ 8190], batch= 87/128, current_bsize= 64, baccuracy: 75.0%, bclass_accuracy:[ 67, 67,100,100,100,100, 25, 67, 67,100,100, 70, 20,100,100,]\n","loss: 0.962607, [ 5568/ 8190], batch= 88/128, current_bsize= 64, baccuracy: 59.4%, bclass_accuracy:[ 60,100,100, 75,100, 86, 25, 80, 67, 25,100,100, 22, 57, 80,]\n","loss: 0.536235, [ 5632/ 8190], batch= 89/128, current_bsize= 64, baccuracy: 82.8%, bclass_accuracy:[100, 75,100,100, 50, 83, 67,100,100,100,100,100, 20, 80, 80,]\n","loss: 0.608334, [ 5696/ 8190], batch= 90/128, current_bsize= 64, baccuracy: 84.4%, bclass_accuracy:[100,100,100, 50,100,100,100, 67, 86,100,100, 60, 67, 60,100,]\n","loss: 0.763909, [ 5760/ 8190], batch= 91/128, current_bsize= 64, baccuracy: 81.2%, bclass_accuracy:[ 80, 60, 80,100, 67,100,100, 80,100,100,100, 50, 75, 75, 75,]\n","loss: 0.798713, [ 5824/ 8190], batch= 92/128, current_bsize= 64, baccuracy: 73.4%, bclass_accuracy:[ 57,100, 71, 50,100, 86,100, 86, 71,100,100, 17,100,100, 60,]\n","loss: 0.597075, [ 5888/ 8190], batch= 93/128, current_bsize= 64, baccuracy: 84.4%, bclass_accuracy:[ 64,100,100, 50,100,100, 67,100,100,100,100, 33,100, 88, 67,]\n","loss: 0.615981, [ 5952/ 8190], batch= 94/128, current_bsize= 64, baccuracy: 78.1%, bclass_accuracy:[100,100, 86, 67,100, 75, 75, 75,100,100,100,  0, 33,100, 50,]\n","loss: 0.838273, [ 6016/ 8190], batch= 95/128, current_bsize= 64, baccuracy: 70.3%, bclass_accuracy:[100,100,100, 25,  0,100,100, 88,100, 40, 60,  0, 50,100, 40,]\n","loss: 0.808182, [ 6080/ 8190], batch= 96/128, current_bsize= 64, baccuracy: 70.3%, bclass_accuracy:[ 83,100,100,100, 75, 67,100, 83,100, 67,100,  0, 33, 75,100,]\n","loss: 0.846347, [ 6144/ 8190], batch= 97/128, current_bsize= 64, baccuracy: 71.9%, bclass_accuracy:[ 86,100,100, 67, 75,100, 67, 75, 83, 33,100, 40, 67,  0, 50,]\n","loss: 0.693771, [ 6208/ 8190], batch= 98/128, current_bsize= 64, baccuracy: 76.6%, bclass_accuracy:[ 80, 50,100,100, 67,100, 50, 88, 80,100,100, 67, 43, 75, 75,]\n","loss: 0.751654, [ 6272/ 8190], batch= 99/128, current_bsize= 64, baccuracy: 73.4%, bclass_accuracy:[100,100,100,100,100,100,  0, 50,100, 33,100, 80, 67, 67, 40,]\n","loss: 0.726524, [ 6336/ 8190], batch=100/128, current_bsize= 64, baccuracy: 78.1%, bclass_accuracy:[ 83,100,100, 50,100,100, 25, 67,100,100,100,100, 40, 33, 33,]\n","loss: 0.492048, [ 6400/ 8190], batch=101/128, current_bsize= 64, baccuracy: 89.1%, bclass_accuracy:[ 75,100, 86,100,100,100, 75, 89,100,100,100,100,  0,100, 80,]\n","loss: 0.797704, [ 6464/ 8190], batch=102/128, current_bsize= 64, baccuracy: 73.4%, bclass_accuracy:[ 33,100, 71,100, 50, 40,100, 92,100, 50,100,100,  0, 50,100,]\n","loss: 0.814994, [ 6528/ 8190], batch=103/128, current_bsize= 64, baccuracy: 70.3%, bclass_accuracy:[ 80, 80, 70,100,100, 50,100, 57, 88, 33,100, 80,  0, 67,100,]\n","loss: 0.865702, [ 6592/ 8190], batch=104/128, current_bsize= 64, baccuracy: 73.4%, bclass_accuracy:[ 50, 67, 75,100, 50, 80,100, 86,100, 50,100, 83, 50, 83, 67,]\n","loss: 0.633777, [ 6656/ 8190], batch=105/128, current_bsize= 64, baccuracy: 73.4%, bclass_accuracy:[ 82,100,100, 50,100, 89, 67, 67,100, 67, 50, 71, 50, 50, 40,]\n","loss: 0.622833, [ 6720/ 8190], batch=106/128, current_bsize= 64, baccuracy: 84.4%, bclass_accuracy:[ 89,100,100,100,100,100,  0, 80,100,100,100, 50, 67,100,100,]\n","loss: 0.665259, [ 6784/ 8190], batch=107/128, current_bsize= 64, baccuracy: 78.1%, bclass_accuracy:[100, 80,100, 67, 67,100, 57, 75, 67, 75,100, 57, 75,100,100,]\n","loss: 0.777993, [ 6848/ 8190], batch=108/128, current_bsize= 64, baccuracy: 60.9%, bclass_accuracy:[100,100,100,100,  0, 83,100, 71, 40,100, 50,  0, 50, 40,100,]\n","loss: 0.584562, [ 6912/ 8190], batch=109/128, current_bsize= 64, baccuracy: 78.1%, bclass_accuracy:[ 83, 60,100,100,100,100,100, 50,100,100, 75, 56, 71,100, 50,]\n","loss: 0.634279, [ 6976/ 8190], batch=110/128, current_bsize= 64, baccuracy: 84.4%, bclass_accuracy:[100,100,100,100, 50,100,100,100,100,  0,100, 67, 75,100, 33,]\n","loss: 0.784686, [ 7040/ 8190], batch=111/128, current_bsize= 64, baccuracy: 67.2%, bclass_accuracy:[ 50, 50,100,100, 50, 75,100,100, 88, 75,100, 71, 40, 33, 40,]\n","loss: 0.533175, [ 7104/ 8190], batch=112/128, current_bsize= 64, baccuracy: 84.4%, bclass_accuracy:[100,100, 75,100, 50, 50,100,100,100,100,100,100, 50,100, 67,]\n","loss: 0.683621, [ 7168/ 8190], batch=113/128, current_bsize= 64, baccuracy: 81.2%, bclass_accuracy:[100, 50, 86,100,  0,100,100, 50, 83,100,100,100, 43, 75, 83,]\n","loss: 0.711557, [ 7232/ 8190], batch=114/128, current_bsize= 64, baccuracy: 71.9%, bclass_accuracy:[ 60, 50,100, 83,100, 75, 67,100,100, 75,100, 86, 17, 25,100,]\n","loss: 0.710321, [ 7296/ 8190], batch=115/128, current_bsize= 64, baccuracy: 75.0%, bclass_accuracy:[ 43,100, 83, 67, 50, 75, 25, 75,100,100,100, 75, 83, 60,100,]\n","loss: 0.695792, [ 7360/ 8190], batch=116/128, current_bsize= 64, baccuracy: 70.3%, bclass_accuracy:[ 71, 75, 75,100,100, 67,  0, 62, 88,100,100, 50, 83,100, 50,]\n","loss: 0.556786, [ 7424/ 8190], batch=117/128, current_bsize= 64, baccuracy: 84.4%, bclass_accuracy:[ 82,100,100,100,100,100,  0, 75, 83, 50,100, 67, 86,100,100,]\n","loss: 0.494465, [ 7488/ 8190], batch=118/128, current_bsize= 64, baccuracy: 89.1%, bclass_accuracy:[100,100,100,100,100,100,100,100, 89,100,100, 86, 33, 71, 50,]\n","loss: 0.452397, [ 7552/ 8190], batch=119/128, current_bsize= 64, baccuracy: 89.1%, bclass_accuracy:[100,100,100,100,100,100,100, 88,100,100,100,100, 57, 80, 50,]\n","loss: 0.736108, [ 7616/ 8190], batch=120/128, current_bsize= 64, baccuracy: 73.4%, bclass_accuracy:[100,100,100, 86,100,100,100, 80,100, 50,100, 56, 50,100, 17,]\n","loss: 0.582843, [ 7680/ 8190], batch=121/128, current_bsize= 64, baccuracy: 82.8%, bclass_accuracy:[100, 75,100,100,100, 86, 50, 80,100,  0,100, 73, 60,100,100,]\n","loss: 0.667782, [ 7744/ 8190], batch=122/128, current_bsize= 64, baccuracy: 78.1%, bclass_accuracy:[100,100, 80,100,100,100,100, 71,100,100,100, 80, 20,  0, 86,]\n","loss: 0.577259, [ 7808/ 8190], batch=123/128, current_bsize= 64, baccuracy: 82.8%, bclass_accuracy:[100,100, 80,100,100,100,100, 88, 88,100,100, 60, 75, 40, 80,]\n","loss: 0.769169, [ 7872/ 8190], batch=124/128, current_bsize= 64, baccuracy: 73.4%, bclass_accuracy:[ 50, 50,100,100,  0,100,100,100,100, 25,100, 33, 82, 60, 60,]\n","loss: 0.477740, [ 7936/ 8190], batch=125/128, current_bsize= 64, baccuracy: 84.4%, bclass_accuracy:[ 80,100,100, 67,100,100,100,100,100,100,100, 40, 80, 67, 67,]\n","loss: 0.737140, [ 8000/ 8190], batch=126/128, current_bsize= 64, baccuracy: 73.4%, bclass_accuracy:[ 33, 80,100, 25, 33, 75,  0, 88,100, 83,100, 50,100, 25, 80,]\n","loss: 0.667995, [ 8064/ 8190], batch=127/128, current_bsize= 64, baccuracy: 71.9%, bclass_accuracy:[ 88,  0,100, 33,  0, 60,100, 86,100,100, 60, 29, 83, 50,100,]\n","loss: 0.454879, [ 8128/ 8190], batch=128/128, current_bsize= 62, baccuracy: 85.5%, bclass_accuracy:[100,100, 83,100, 33,100,100, 50,100, 67,100, 80, 83,100, 80,]\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/Colab Notebooks/adl-cw/work/dcase.py\", line 309, in <module>\n","    main(parser.parse_args())\n","  File \"/content/drive/MyDrive/Colab Notebooks/adl-cw/work/dcase.py\", line 296, in main\n","    trainer.train()\n","  File \"/content/drive/MyDrive/Colab Notebooks/adl-cw/work/dcase.py\", line 165, in train\n","    total_batch_count, total_class_count, total_loss, total_confusion_matrix = self.test(self.test_dataloader)\n","  File \"/content/drive/MyDrive/Colab Notebooks/adl-cw/work/dcase.py\", line 200, in test\n","    logits = self.model(X)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/content/drive/MyDrive/Colab Notebooks/adl-cw/work/audiocnn.py\", line 56, in forward\n","    logits = self.cnn_neuro_stack(x)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\", line 141, in forward\n","    input = module(input)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\", line 446, in forward\n","    return self._conv_forward(input, self.weight, self.bias)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\", line 443, in _conv_forward\n","    self.padding, self.dilation, self.groups)\n","KeyboardInterrupt\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"qRBQ0-jLEkRz"},"execution_count":null,"outputs":[]}]}